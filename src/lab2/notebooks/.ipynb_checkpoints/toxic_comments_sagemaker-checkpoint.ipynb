{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Text Classification using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been sourced from the following blogs by Kaushal Trivedi [1](https://medium.com/huggingface/introducing-fastbert-a-simple-deep-learning-library-for-bert-models-89ff763ad384) [2](https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d) and the associated [GitHub repos](https://github.com/kaushaltrivedi/fast-bert)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets understand whats happening here - this is the way we are using SageMaker to fine tune Hugging Face BERT models \n",
    "\n",
    "![SageMaker Architecture](../img/sagemaker-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle components of the architecture\n",
    "\n",
    "*Container* - we start off this lab by building our own container, and using SageMaker Service to train it and deploy the resultant model. I have commented it out because as of Nov 28 2019 the resultant container cannot train properly due to an unmet dependancy. As of this writing I am still debugging it. It takes around 22 mins of clock time to build this container and push it to ECR, from scratch on ml.p2.xlarge.\n",
    "\n",
    "Once the container is ready we proceed with the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!../container/build_and_push.sh\n",
    "#We have prebuilt containers and made them available to be pulled in us-east-1 and us-west-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from sagemaker.predictor import json_serializer\n",
    "import json\n",
    "import numpy as np\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location for train.csv, val.csv and labels.csv\n",
    "DATA_PATH = Path(\"../sm-data/\")   \n",
    "\n",
    "# Location for storing training_config.json\n",
    "CONFIG_PATH = DATA_PATH/'config'\n",
    "CONFIG_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "suffix = str(np.random.uniform())[4:9]\n",
    "\n",
    "# S3 bucket name\n",
    "bucket = 'toxic-pytorch-sagemaker-' + suffix\n",
    "\n",
    "# Prefix for S3 bucket for input and output\n",
    "prefix = 'toxic_comments/input'\n",
    "prefix_output = 'toxic_comments/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 mb s3://{bucket}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters & Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 8e-5,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"lr_schedule\": \"warmup_cosine\",\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"optimizer_type\": \"adamw\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"run_text\": \"toxic comments\",\n",
    "    \"finetuned_model\": None,\n",
    "    \"do_lower_case\": \"True\",\n",
    "    \"train_file\": \"train.csv\",\n",
    "    \"val_file\": \"val.csv\",\n",
    "    \"label_file\": \"labels.csv\",\n",
    "    \"text_col\": \"comment_text\",\n",
    "    \"label_col\": '[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]',\n",
    "    \"multi_label\": \"True\",\n",
    "    \"grad_accumulation_steps\": \"1\",\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"fp16\": \"True\",\n",
    "    \"model_type\": \"roberta\",\n",
    "    \"model_name\": \"roberta-base\",\n",
    "    \"logging_steps\": \"300\"\n",
    "}\n",
    "\n",
    "with open(CONFIG_PATH/'training_config.json', 'w') as f:\n",
    "    json.dump(training_config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper feature to upload data\n",
    "# from your local machine to S3 bucket.\n",
    "\n",
    "s3_input = session.upload_data(DATA_PATH, bucket=bucket , key_prefix=prefix)\n",
    "\n",
    "session.upload_data(str(DATA_PATH/'val.csv'), bucket=bucket , key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.upload_data(str(DATA_PATH/'labels.csv'), bucket=bucket , key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.upload_data(str(DATA_PATH/'train.csv'), bucket=bucket , key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Estimator and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws configure get region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#account = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "#region = session.boto_session.region_name\n",
    "\n",
    "#image = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-bert:1.0-gpu-py36\".format(account, region)\n",
    "\n",
    "#Please use only the following images - \n",
    "#US East 1 - 111652037296.dkr.ecr.us-west-2.amazonaws.com/chazarey-sagemaker-fast-bert:1.0-gpu-py36\n",
    "#US West 2 - 111652037296.dkr.ecr.us-east-1.amazonaws.com/chazarey-sagemaker-fast-bert-copied:1.0-gpu-py36\n",
    "\n",
    "image = \"111652037296.dkr.ecr.us-west-2.amazonaws.com/chazarey-sagemaker-fast-bert:1.0-gpu-py36\"\n",
    "#TODO Convert this to using SM Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"s3://{}/{}\".format(bucket, prefix_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(image, \n",
    "                                          role,\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.p3.8xlarge', \n",
    "                                          output_path=output_path, \n",
    "                                          base_job_name='toxic-comments',\n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          sagemaker_session=session\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(s3_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model to hosting service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(1, \n",
    "                             'ml.m5.large', \n",
    "                             endpoint_name='bert-toxic-comments', \n",
    "                             serializer=json_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Invoke the Endpoint\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "sample_payload='{\"text\": \"this is really really good thanks for recommending!!\"}'\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName='bert-toxic-comments',\n",
    "    Body=sample_payload,\n",
    "    ContentType='application/json'\n",
    ")\n",
    "print('Our result for this payload is: {}'.format(response['Body'].read().decode('ascii')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
