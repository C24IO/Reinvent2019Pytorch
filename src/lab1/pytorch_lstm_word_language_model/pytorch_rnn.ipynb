{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-level language modeling using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference Source: PyTorch Example from SageMaker](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/pytorch_lstm_word_language_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.p2.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See [the documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGet the execution role for the notebook instance. This is the IAM role that you created when you created your notebook instance. You pass the role to the tuning job.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "'''\n",
    "A session stores configuration state and allows you to create service clients and resources.\n",
    "sagemaker.session.Session - AWS service calls are delegated to an underlying Boto3 session, \n",
    "which by default is initialized using the AWS configuration chain. \n",
    "When you make an Amazon SageMaker API call that accesses an S3 bucket location and one is not specified, \n",
    "the Session creates a default bucket based on a naming convention which includes the current AWS account ID.\n",
    "'''\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "'''\n",
    "Form of the name of the bucket - sagemaker-{region}-{AWS account ID} Return the name of the default bucket to use in relevant Amazon SageMaker interactions.\n",
    "\n",
    "'''\n",
    "\n",
    "prefix = 'sagemaker/DEMO-pytorch-rnn-lstm'\n",
    "\n",
    "'''\n",
    "Used later\n",
    "'''\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "'''\n",
    "Get the execution role for the notebook instance. This is the IAM role that you created when you created your notebook instance. You pass the role to the tuning job.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Getting the data\n",
    "As mentioned above we are going to use [the wikitext-2 raw data](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/). This data is from Wikipedia and is licensed CC-BY-SA-3.0. Before you use this data for any other purpose than this example, you should understand the data license, described at https://creativecommons.org/licenses/by-sa/3.0/\n",
    "\n",
    "This dataset is provided by SalesForce, The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. What we have here is a good example of how English language flows.\n",
    "\n",
    "### Examples\n",
    "= Gold dollar =\n",
    "\n",
    " The gold dollar or gold one @-@ dollar piece was a coin struck as a regular issue by the United States Bureau of the Mint from 1849 to 1889 . The coin had three types over its lifetime , all designed by Mint Chief Engraver James B. Longacre . The Type 1 issue had the smallest diameter of any United States coin ever minted .\n",
    " A gold dollar had been proposed several times in the 1830s and 1840s , but was not initially adopted . Congress was finally galvanized into action by the increased supply of bullion caused by the California gold rush , and in 1849 authorized a gold dollar . In its early years , silver coins were being hoarded or exported , and the gold dollar found a ready place in commerce . Silver again circulated after Congress in 1853 required that new coins of that metal be made lighter , and the gold dollar became a rarity in commerce even before federal coins vanished from circulation because of the economic disruption caused by the American Civil War .\n",
    " \n",
    " = Super Mario Land =\n",
    "\n",
    " Super Mario Land is a 1989 side @-@ scrolling platform video game , the first in the Super Mario Land series , developed and published by Nintendo as a launch title for their Game Boy handheld game console . In gameplay similar to that of the 1985 Super Mario Bros. , but resized for the smaller device 's screen , the player advances Mario to the end of 12 levels by moving to the right and jumping across platforms to avoid enemies and pitfalls . Unlike other Mario games , Super Mario Land is set in Sarasaland , a new environment depicted in line art , and Mario pursues Princess Daisy . The game introduces two Gradius @-@ style shooter levels .\n",
    " At Nintendo CEO Hiroshi Yamauchi 's request , Game Boy creator Gunpei Yokoi 's Nintendo R & D1 developed a Mario game to sell the new console . It was the first portable version of Mario and the first to be made without Mario creator and Yokoi protégé Shigeru Miyamoto . Accordingly , the development team shrunk Mario gameplay elements for the device and used some elements inconsistently from the series . Super Mario Land was expected to showcase the console until Nintendo of America bundled Tetris with new Game Boys . The game launched alongside the Game Boy first in Japan ( April 1989 ) and later worldwide . Super Mario Land was later rereleased for the Nintendo 3DS via Virtual Console in 2011 again as a launch title , which featured some tweaks to the game 's presentation .\n",
    " Initial reviews were laudatory . Reviewers were satisfied with the smaller Super Mario Bros. , but noted its short length . They considered it among the best of the Game Boy launch titles . The handheld console became an immediate success and Super Mario Land ultimately sold over 18 million copies , more than that of Super Mario Bros. 3 . Both contemporaneous and retrospective reviewers praised the game 's soundtrack . Later reviews were critical of the compromises made in development and noted Super Mario Land 's deviance from series norms . The game begot a series of sequels , including the 1992 Super Mario Land 2 : 6 Golden Coins , 1994 Wario Land : Super Mario Land 3 , and 2011 Super Mario 3D Land , though many of the original 's mechanics were not revisited . The game was included in several top Game Boy game lists and debuted Princess Daisy as a recurring Mario series character .\n",
    " \n",
    "= = = Sinclair Scientific Programmable = = =\n",
    "\n",
    " The Sinclair Scientific Programmable was introduced in 1975 , with the same case as the Sinclair Oxford . It was larger than the Scientific , at 73 by 155 by 34 millimetres ( 2 @.@ 9 in × 6 @.@ 1 in × 1 @.@ 3 in ) , and used a larger  battery , but could also be powered by mains electricity .\n",
    " It had 24 @-@ step programming abilities , which meant it was highly limited for many purposes . It also lacked functions for the natural logarithm and exponential function . Constants used in programs were required to be integers , and the programming was wasteful , with start and end quotes needed to use a constant in a program .\n",
    " However , included with the calculator was a library of over 120 programs that that performed common operations in mathematics , geometry , statistics , finance , physics , electronics , engineering , as well as fluid mechanics and materials science . The full library of standard programs contained over 400 programs in the Sinclair Program Library .\n",
    "\n",
    "### Dataset statistics\n",
    "In comparison to the Mikolov processed version of the Penn Treebank (PTB), the WikiText datasets are larger. WikiText-2 aims to be of a similar size to the PTB while WikiText-103 contains all articles extracted from Wikipedia. The WikiText datasets also retain numbers (as opposed to replacing them with N), case (as opposed to all text being lowercased), and punctuation (as opposed to stripping them out).\n",
    "\n",
    "![Dataset statistics](../img/dataset-statistics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  wikitext-2-raw-v1.zip\n",
      "  inflating: wikitext-2-raw/wiki.test.raw  \n",
      "  inflating: wikitext-2-raw/wiki.valid.raw  \n",
      "  inflating: wikitext-2-raw/wiki.train.raw  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2019-11-26 22:56:23--  http://research.metamind.io.s3.amazonaws.com/wikitext/wikitext-2-raw-v1.zip\n",
      "Resolving research.metamind.io.s3.amazonaws.com (research.metamind.io.s3.amazonaws.com)... 52.216.226.144\n",
      "Connecting to research.metamind.io.s3.amazonaws.com (research.metamind.io.s3.amazonaws.com)|52.216.226.144|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4721645 (4.5M) [application/zip]\n",
      "Saving to: ‘wikitext-2-raw-v1.zip.5’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  311K 15s\n",
      "    50K .......... .......... .......... .......... ..........  2% 1.76M 9s\n",
      "   100K .......... .......... .......... .......... ..........  3%  934K 7s\n",
      "   150K .......... .......... .......... .......... ..........  4% 80.5M 5s\n",
      "   200K .......... .......... .......... .......... ..........  5%  629K 6s\n",
      "   250K .......... .......... .......... .......... ..........  6% 81.1M 5s\n",
      "   300K .......... .......... .......... .......... ..........  7% 90.1M 4s\n",
      "   350K .......... .......... .......... .......... ..........  8% 1.86M 4s\n",
      "   400K .......... .......... .......... .......... ..........  9% 47.2M 3s\n",
      "   450K .......... .......... .......... .......... .......... 10%  959K 3s\n",
      "   500K .......... .......... .......... .......... .......... 11% 95.1M 3s\n",
      "   550K .......... .......... .......... .......... .......... 13%  129M 3s\n",
      "   600K .......... .......... .......... .......... .......... 14%  172M 2s\n",
      "   650K .......... .......... .......... .......... .......... 15% 92.5M 2s\n",
      "   700K .......... .......... .......... .......... .......... 16%  114M 2s\n",
      "   750K .......... .......... .......... .......... .......... 17%  117M 2s\n",
      "   800K .......... .......... .......... .......... .......... 18% 1.95M 2s\n",
      "   850K .......... .......... .......... .......... .......... 19% 62.8M 2s\n",
      "   900K .......... .......... .......... .......... .......... 20%  959K 2s\n",
      "   950K .......... .......... .......... .......... .......... 21%  101M 2s\n",
      "  1000K .......... .......... .......... .......... .......... 22%  109M 2s\n",
      "  1050K .......... .......... .......... .......... .......... 23%  145M 2s\n",
      "  1100K .......... .......... .......... .......... .......... 24%  133M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 26%  144M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 27%  129M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 28%  202M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 29%  156M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 30%  222M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 31%  212M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 32%  375M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 33%  254M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 34%  326M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 35% 2.05M 1s\n",
      "  1650K .......... .......... .......... .......... .......... 36%  292M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 37%  380M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 39%  139M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 40%  148M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 41%  966K 1s\n",
      "  1900K .......... .......... .......... .......... .......... 42% 84.4M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 43%  146M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 44%  130M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 45%  206M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 46%  202M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 47%  361M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 48%  221M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 49%  176M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 50%  200M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 52%  187M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 53%  105M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 54%  201M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 55%  296M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 56%  163M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 57%  151M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 58%  145M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 59%  160M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 60%  329M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 61%  239M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 62%  375M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 63%  376M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 65%  331M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 66%  310M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 67%  361M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 68%  383M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 69% 2.28M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 70%  139M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 71%  381M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 72%  129M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 73%  175M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 74%  966K 0s\n",
      "  3450K .......... .......... .......... .......... .......... 75%  130M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 76%  106M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 78% 96.3M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 79%  112M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 80%  130M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 81%  202M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 82%  136M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 83%  183M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 84%  156M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 85%  172M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 86%  212M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 87%  120M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 88%  109M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 90%  315M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 91%  381M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 92%  387M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 93%  323M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 94%  308M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 95%  373M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 96%  356M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 97%  348M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 98%  316M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 99%  371M 0s\n",
      "  4600K ..........                                            100%  362M=0.7s\n",
      "\n",
      "2019-11-26 22:56:24 (6.92 MB/s) - ‘wikitext-2-raw-v1.zip.5’ saved [4721645/4721645]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget http://research.metamind.io.s3.amazonaws.com/wikitext/wikitext-2-raw-v1.zip\n",
    "unzip -n wikitext-2-raw-v1.zip\n",
    "cd wikitext-2-raw\n",
    "mv wiki.test.raw test && mv wiki.train.raw train && mv wiki.valid.raw valid\n",
    "# Moving the pre-divided datasets into Test, Train and Validation directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview what data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " = Valkyria Chronicles III = \n",
      " \n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n"
     ]
    }
   ],
   "source": [
    "!head -5 wikitext-2-raw/train\n",
    "#Lets see how the train dataset looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-111652037296/sagemaker/DEMO-pytorch-rnn-lstm\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='wikitext-2-raw', bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "'''\n",
    "S3 object key name prefix (default: ‘data’). S3 uses the prefix to create a directory structure for the bucket content that it display in the S3 console.\n",
    "\n",
    "Tree of the datasets - \n",
    "\n",
    "├── wikitext-2-raw\n",
    "│   ├── test\n",
    "│   ├── train\n",
    "│   └── valid\n",
    "'''\n",
    "\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "We need to provide a training script that can run on the SageMaker platform. The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_OUTPUT_DATA_DIR`: A string representing the filesystem path to write output artifacts to. Output artifacts may\n",
    "  include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed\n",
    "  and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method,\n",
    "the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "The script that we will use in this example is stored in GitHub repo \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/tree/training-scripts](https://github.com/awslabs/amazon-sagemaker-examples/tree/training-scripts), \n",
    "under the branch `training-scripts`. It is a public repo so we don't need authentication to access it. Let's specify the `git_config` argument here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance. \n",
    "\n",
    "For example, the script run by this notebook: \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/train.py](https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/train.py). \n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current example we also need to provide source directory, because training script imports data and model classes from other modules. The source directory is \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/](https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/). We should provide 'pytorch-rnn-scripts' for `source_dir` when creating the Estimator object, which is a relative path inside the Git repository. \n",
    "\n",
    "\n",
    "Lets see the training script in details - this training script is located here - \n",
    "\n",
    "```bash\n",
    "├── pytorch-rnn-scripts\n",
    "│   ├── data.py\n",
    "│   ├── generate.py\n",
    "│   ├── __init__.py\n",
    "│   ├── rnn.py\n",
    "│   └── train.py\n",
    "```\n",
    "\n",
    "```python\n",
    "import data\n",
    "```\n",
    "\n",
    "Here we import data.py, data.py has functions for tokenizing and creating a corpus for consumptions. A few relevant details here - [tokens](https://github.com/nicolas-ivanov/tf_seq2seq_chatbot/issues/15#issuecomment-246106807)\n",
    "\n",
    "Then we have hyperparamters being passed to this script, you can see this in the training blob\n",
    "\n",
    "\n",
    "```python\n",
    "# Hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "parser.add_argument('--emsize', type=int, default=200,\n",
    "                    help='size of word embeddings')\n",
    "parser.add_argument('--nhid', type=int, default=200,\n",
    "                    help='number of hidden units per layer')\n",
    "parser.add_argument('--nlayers', type=int, default=2,\n",
    "                    help='number of layers')\n",
    "parser.add_argument('--lr', type=float, default=20,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--clip', type=float, default=0.25,\n",
    "                    help='gradient clipping')\n",
    "parser.add_argument('--epochs', type=int, default=40,\n",
    "                    help='upper epoch limit')\n",
    "parser.add_argument('--batch_size', type=int, default=20, metavar='N',\n",
    "                    help='batch size')\n",
    "parser.add_argument('--bptt', type=int, default=35,\n",
    "                    help='sequence length')\n",
    "parser.add_argument('--dropout', type=float, default=0.2,\n",
    "                    help='dropout applied to layers (0 = no dropout)')\n",
    "parser.add_argument('--tied', type=bool, default=False,\n",
    "                    help='tie the word embedding and softmax weights')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--log-interval', type=int, default=200, metavar='N',\n",
    "                    help='report interval')\n",
    "```\n",
    "Then we have details of file paths - \n",
    "\n",
    "```python\n",
    "# Data and model checkpoints/otput directories from the container environment\n",
    "parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "parser.add_argument('--data-dir', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "```\n",
    "\n",
    "Here are some logs from when a job like this was run - \n",
    "\n",
    "```json\n",
    "SM_TRAINING_ENV=\n",
    "{\n",
    "    \"additional_framework_parameters\": {},\n",
    "    \"channel_input_dirs\": {\n",
    "        \"training\": \"/opt/ml/input/data/training\"\n",
    "    },\n",
    "    \"current_host\": \"algo-1\",\n",
    "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
    "    \"hosts\": [\n",
    "        \"algo-1\"\n",
    "    ],\n",
    "    \"hyperparameters\": {\n",
    "        \"epochs\": 6,\n",
    "        \"tied\": true\n",
    "    },\n",
    "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
    "    \"input_data_config\": {\n",
    "        \"training\": {\n",
    "            \"RecordWrapperType\": \"None\",\n",
    "            \"S3DistributionType\": \"FullyReplicated\",\n",
    "            \"TrainingInputMode\": \"File\"\n",
    "        }\n",
    "    },\n",
    "    \"input_dir\": \"/opt/ml/input\",\n",
    "    \"is_master\": true,\n",
    "    \"job_name\": \"sagemaker-pytorch-2019-11-26-19-32-08-962\",\n",
    "    \"log_level\": 20,\n",
    "    \"master_hostname\": \"algo-1\",\n",
    "    \"model_dir\": \"/opt/ml/model\",\n",
    "    \"module_dir\": \"s3://sagemaker-us-west-2-111652037296/sagemaker-pytorch-2019-11-26-19-32-08-962/source/sourcedir.tar.gz\",\n",
    "    \"module_name\": \"train\",\n",
    "    \"network_interface_name\": \"eth0\",\n",
    "    \"num_cpus\": 4,\n",
    "    \"num_gpus\": 1,\n",
    "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
    "    \"output_dir\": \"/opt/ml/output\",\n",
    "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
    "    \"resource_config\": {\n",
    "        \"current_host\": \"algo-1\",\n",
    "        \"hosts\": [\n",
    "            \"algo-1\"\n",
    "        ],\n",
    "        \"network_interface_name\": \"eth0\"\n",
    "    },\n",
    "    \"user_entry_point\": \"train.py\"\n",
    "}\n",
    "```\n",
    "\n",
    "Here are some environment variables - \n",
    "\n",
    "```json\n",
    "SM_USER_ARGS=[\"--epochs\",\"6\",\"--tied\",\"True\"]\n",
    "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
    "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
    "SM_HP_TIED=true\n",
    "SM_HP_EPOCHS=6\n",
    "PYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
    "Invoking script with the following command:\n",
    "/usr/bin/python -m train --epochs 6 --tied True\n",
    "\n",
    "Namespace(batch_size=20, bptt=35, clip=0.25, data_dir='/opt/ml/input/data/training', dropout=0.2, emsize=200, epochs=6, log_interval=200, lr=20, model_dir='/opt/ml/model', nhid=200, nlayers=2, output_data_dir='/opt/ml/output/data', seed=1111, tied=True)\n",
    "```\n",
    "\n",
    "You can find the logs by going to the training jobs in the Amazon SageMaker Dashboard\n",
    "\n",
    "```python\n",
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(args.seed)\n",
    "```\n",
    "\n",
    "This seed you can seed was 1111 in the above example. You can use torch.manual_seed() to seed the RNG for all devices (both CPU and CUDA). Completely reproducible results are not guaranteed across PyTorch releases, individual commits or different platforms. Furthermore, results need not be reproducible between CPU and GPU executions, even when using identical seeds. However, in order to make computations deterministic on your specific problem on one specific platform and PyTorch release, there are a couple of steps to take. This is one of these steps. More details [here(https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "\n",
    "\n",
    "Now we load the corpus created by data.py\n",
    "\n",
    "```python\n",
    "print('Load data')\n",
    "corpus = data.Corpus(args.data_dir)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in Pytorch\n",
    "\n",
    "Now at this stage after a bit more setup - we load the model \n",
    "\n",
    "```python\n",
    "ntokens = len(corpus.dictionary)\n",
    "rnn_type = 'LSTM'\n",
    "model = RNNModel(rnn_type, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout, args.tied).to(device)\n",
    "```\n",
    "\n",
    "We have defined the model in - rnn.py\n",
    "\n",
    "We are using LSTM which is a variant of RNN\n",
    "\n",
    "![The LSTM Cell](../img/The_LSTM_cell-600.400.png)\n",
    "\n",
    "Soure of image - [Guillaume Chevalier from Wikipedia](https://en.wikipedia.org/wiki/Long_short-term_memory#/media/File:The_LSTM_cell.png)\n",
    "\n",
    "Now you can see how the above architecture is setup, we can understand this better using the following image as a resource. \n",
    "\n",
    "![The LSTM Cell - in series](../img/nct-seq2seq.png)\n",
    "\n",
    "Soure of image - [Deep Learning for Chatbots, Part 1 – Introduction](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/)\n",
    "\n",
    "```python\n",
    "self.drop = nn.Dropout(dropout)\n",
    "self.encoder = nn.Embedding(ntoken, ninp)\n",
    "self.rnn = getattr(nn, 'LSTM')(ninp, nhid, nlayers, dropout=dropout)\n",
    "\n",
    "nn - Base class for all neural network modules.\n",
    "ninp - size of word embeddings - emsize=200\n",
    "nhid - number of hidden units per layer - nhid=200\n",
    "nlayers - number of layers - nlayers=2\n",
    "dropout - dropout=0.2\n",
    "tied - tie the word embedding and softmax weights - tied=True\n",
    "```\n",
    "\n",
    "Then you can see the necessary functions of RNNs - such as - forward pass and initialize hidden weights. \n",
    "\n",
    "```python\n",
    "def init_weights(self):\n",
    "def forward(self, input, hidden):\n",
    "def init_hidden(self, bsz):\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the training script \n",
    "\n",
    "We have function to batch up the corpus -\n",
    "\n",
    "```python\n",
    "def get_batch(source, i):\n",
    "get_batch subdivides the source data into chunks of length args.bptt.\n",
    "```\n",
    "\n",
    "We have a function for Training, Validation\n",
    "\n",
    "```python\n",
    "def train():\n",
    "def evaluate(data_source):\n",
    "```\n",
    "\n",
    "We have the training loop\n",
    "\n",
    "```python\n",
    "for epoch in range(1, args.epochs+1):\n",
    "```\n",
    "\n",
    "We checkpoint the model - \n",
    "\n",
    "```python\n",
    "print('Saving the best model: {}'.format(best_state))\n",
    "with open(checkpoint_path, 'wb') as f:\n",
    "    torch.save(model.state_dict(), f)\n",
    "with open(checkpoint_state_path, 'w') as f:\n",
    "```\n",
    "    \n",
    "&\n",
    "\n",
    "```python\n",
    "# Load the best saved model.\n",
    "with open(checkpoint_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    # after load the rnn params are not a continuous chunk of memory\n",
    "    # this makes them a continuous chunk, and will speed up forward pass\n",
    "    model.rnn.flatten_parameters()\n",
    "```\n",
    "\n",
    "&\n",
    "\n",
    "Save the model - \n",
    "\n",
    "```python\n",
    "# Move the best model to cpu and resave it\n",
    "with open(model_path, 'wb') as f:\n",
    "    torch.save(model.cpu().state_dict(), f)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training in SageMaker\n",
    "The PyTorch class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script and source directory, an IAM role, the number of training instances, and the training instance type. In this case we will run our training job on ```ml.p2.xlarge``` instance. As you can see in this example you can also specify hyperparameters. \n",
    "\n",
    "Here we are using a prebuilt container for training our script, if you want to create your own please navigate to - https://github.com/aws/sagemaker-pytorch-container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.2.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    source_dir='pytorch-rnn-scripts',\n",
    "                    # available hyperparameters: emsize, nhid, nlayers, lr, clip, epochs, batch_size,\n",
    "                    #                            bptt, dropout, tied, seed, log_interval\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6,\n",
    "                        'tied': True\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our PyTorch object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-26 22:56:26 Starting - Starting the training job...\n",
      "2019-11-26 22:56:27 Starting - Launching requested ML instances......\n",
      "2019-11-26 22:57:28 Starting - Preparing the instances for training......\n",
      "2019-11-26 22:58:47 Downloading - Downloading input data\n",
      "2019-11-26 22:58:47 Training - Downloading the training image......\n",
      "2019-11-26 22:59:35 Failed - Training job failed\n",
      ".."
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-pytorch-2019-11-26-22-56-25-314: Failed. Reason: ClientError: Cannot pull algorithm container. Either the image does not exist or its permissions are incorrect.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ba991b5a2d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_rule_job_arn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_job_arn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \"\"\"\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 ),\n\u001b[1;32m   1093\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m             )\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-pytorch-2019-11-26-22-56-25-314: Failed. Reason: ClientError: Cannot pull algorithm container. Either the image does not exist or its permissions are incorrect."
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host\n",
    "### Hosting script\n",
    "We are going to provide custom implementation of `model_fn`, `input_fn`, `output_fn` and `predict_fn` hosting functions in a separate file, which is in the same Git repo as the training script: \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/generate.py](https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/generate.py). \n",
    "We will use Git integration for hosting too since the hosting code is also in the Git repo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also put your training and hosting code in the same file but you would need to add a main guard (`if __name__=='__main__':`) for the training code, so that the container does not inadvertently run it at the wrong point in execution during hosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model into SageMaker\n",
    "The PyTorch model uses a npy serializer and deserializer by default. For this example, since we have a custom implementation of all the hosting functions and plan on using JSON instead, we need a predictor that can serialize and deserialize JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor, json_serializer, json_deserializer\n",
    "\n",
    "class JSONPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(JSONPredictor, self).__init__(endpoint_name, sagemaker_session, json_serializer, json_deserializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since hosting functions implemented outside of train script we can't just use estimator object to deploy the model. Instead we need to create a PyTorchModel object using the latest training job to get the S3 location of the trained model data. Besides model data location in S3, we also need to configure PyTorchModel with the script and source directory (because our `generate` script requires model and data classes from source directory), an IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "trained_model_location = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "model = PyTorchModel(model_data=trained_model_location,\n",
    "                     role=role,\n",
    "                     framework_version='1.0.0',\n",
    "                     entry_point='generate.py',\n",
    "                     source_dir='pytorch-rnn-scripts',\n",
    "                     predictor_cls=JSONPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "\n",
    "Now the model is ready to be deployed at a SageMaker endpoint and we are going to use the `sagemaker.pytorch.model.PyTorchModel.deploy` method to do this. We can use a CPU-based instance for inference (in this case an ml.m4.xlarge), even though we trained on GPU instances, because at the end of training we moved model to cpu before returning it. This way we can load trained model on any device and then move to GPU if CUDA is available. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "We are going to use our deployed model to generate text by providing random seed, temperature (higher will increase diversity) and number of words we would like to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    'seed': 200,\n",
    "    'temperature': 510.0,\n",
    "    'words': 200\n",
    "}\n",
    "response = predictor.predict(input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
