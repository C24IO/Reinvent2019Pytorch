{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-level language modeling using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference Source: PyTorch Example from SageMaker](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk/pytorch_lstm_word_language_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.p2.xlarge notebook instance._\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See [the documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGet the execution role for the notebook instance. This is the IAM role that you created when you created your notebook instance. You pass the role to the tuning job.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "'''\n",
    "A session stores configuration state and allows you to create service clients and resources.\n",
    "sagemaker.session.Session - AWS service calls are delegated to an underlying Boto3 session, \n",
    "which by default is initialized using the AWS configuration chain. \n",
    "When you make an Amazon SageMaker API call that accesses an S3 bucket location and one is not specified, \n",
    "the Session creates a default bucket based on a naming convention which includes the current AWS account ID.\n",
    "'''\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "'''\n",
    "Form of the name of the bucket - sagemaker-{region}-{AWS account ID} Return the name of the default bucket to use in relevant Amazon SageMaker interactions.\n",
    "\n",
    "'''\n",
    "\n",
    "prefix = 'sagemaker/DEMO-pytorch-rnn-lstm'\n",
    "\n",
    "'''\n",
    "Used later\n",
    "'''\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "'''\n",
    "Get the execution role for the notebook instance. This is the IAM role that you created when you created your notebook instance. You pass the role to the tuning job.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Getting the data\n",
    "As mentioned above we are going to use [the wikitext-2 raw data](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/). This data is from Wikipedia and is licensed CC-BY-SA-3.0. Before you use this data for any other purpose than this example, you should understand the data license, described at https://creativecommons.org/licenses/by-sa/3.0/\n",
    "\n",
    "This dataset is provided by SalesForce, The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. What we have here is a good example of how English language flows.\n",
    "\n",
    "### Examples\n",
    "= Gold dollar =\n",
    "\n",
    " The gold dollar or gold one @-@ dollar piece was a coin struck as a regular issue by the United States Bureau of the Mint from 1849 to 1889 . The coin had three types over its lifetime , all designed by Mint Chief Engraver James B. Longacre . The Type 1 issue had the smallest diameter of any United States coin ever minted .\n",
    " A gold dollar had been proposed several times in the 1830s and 1840s , but was not initially adopted . Congress was finally galvanized into action by the increased supply of bullion caused by the California gold rush , and in 1849 authorized a gold dollar . In its early years , silver coins were being hoarded or exported , and the gold dollar found a ready place in commerce . Silver again circulated after Congress in 1853 required that new coins of that metal be made lighter , and the gold dollar became a rarity in commerce even before federal coins vanished from circulation because of the economic disruption caused by the American Civil War .\n",
    " \n",
    " = Super Mario Land =\n",
    "\n",
    " Super Mario Land is a 1989 side @-@ scrolling platform video game , the first in the Super Mario Land series , developed and published by Nintendo as a launch title for their Game Boy handheld game console . In gameplay similar to that of the 1985 Super Mario Bros. , but resized for the smaller device 's screen , the player advances Mario to the end of 12 levels by moving to the right and jumping across platforms to avoid enemies and pitfalls . Unlike other Mario games , Super Mario Land is set in Sarasaland , a new environment depicted in line art , and Mario pursues Princess Daisy . The game introduces two Gradius @-@ style shooter levels .\n",
    " At Nintendo CEO Hiroshi Yamauchi 's request , Game Boy creator Gunpei Yokoi 's Nintendo R & D1 developed a Mario game to sell the new console . It was the first portable version of Mario and the first to be made without Mario creator and Yokoi protégé Shigeru Miyamoto . Accordingly , the development team shrunk Mario gameplay elements for the device and used some elements inconsistently from the series . Super Mario Land was expected to showcase the console until Nintendo of America bundled Tetris with new Game Boys . The game launched alongside the Game Boy first in Japan ( April 1989 ) and later worldwide . Super Mario Land was later rereleased for the Nintendo 3DS via Virtual Console in 2011 again as a launch title , which featured some tweaks to the game 's presentation .\n",
    " Initial reviews were laudatory . Reviewers were satisfied with the smaller Super Mario Bros. , but noted its short length . They considered it among the best of the Game Boy launch titles . The handheld console became an immediate success and Super Mario Land ultimately sold over 18 million copies , more than that of Super Mario Bros. 3 . Both contemporaneous and retrospective reviewers praised the game 's soundtrack . Later reviews were critical of the compromises made in development and noted Super Mario Land 's deviance from series norms . The game begot a series of sequels , including the 1992 Super Mario Land 2 : 6 Golden Coins , 1994 Wario Land : Super Mario Land 3 , and 2011 Super Mario 3D Land , though many of the original 's mechanics were not revisited . The game was included in several top Game Boy game lists and debuted Princess Daisy as a recurring Mario series character .\n",
    " \n",
    "= = = Sinclair Scientific Programmable = = =\n",
    "\n",
    " The Sinclair Scientific Programmable was introduced in 1975 , with the same case as the Sinclair Oxford . It was larger than the Scientific , at 73 by 155 by 34 millimetres ( 2 @.@ 9 in × 6 @.@ 1 in × 1 @.@ 3 in ) , and used a larger  battery , but could also be powered by mains electricity .\n",
    " It had 24 @-@ step programming abilities , which meant it was highly limited for many purposes . It also lacked functions for the natural logarithm and exponential function . Constants used in programs were required to be integers , and the programming was wasteful , with start and end quotes needed to use a constant in a program .\n",
    " However , included with the calculator was a library of over 120 programs that that performed common operations in mathematics , geometry , statistics , finance , physics , electronics , engineering , as well as fluid mechanics and materials science . The full library of standard programs contained over 400 programs in the Sinclair Program Library .\n",
    "\n",
    "### Dataset statistics\n",
    "In comparison to the Mikolov processed version of the Penn Treebank (PTB), the WikiText datasets are larger. WikiText-2 aims to be of a similar size to the PTB while WikiText-103 contains all articles extracted from Wikipedia. The WikiText datasets also retain numbers (as opposed to replacing them with N), case (as opposed to all text being lowercased), and punctuation (as opposed to stripping them out).\n",
    "\n",
    "![Dataset statistics](../img/dataset-statistics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  wikitext-2-raw-v1.zip\n",
      "  inflating: wikitext-2-raw/wiki.test.raw  \n",
      "  inflating: wikitext-2-raw/wiki.valid.raw  \n",
      "  inflating: wikitext-2-raw/wiki.train.raw  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2019-11-28 17:40:55--  http://research.metamind.io.s3.amazonaws.com/wikitext/wikitext-2-raw-v1.zip\n",
      "Resolving research.metamind.io.s3.amazonaws.com (research.metamind.io.s3.amazonaws.com)... 52.216.186.43\n",
      "Connecting to research.metamind.io.s3.amazonaws.com (research.metamind.io.s3.amazonaws.com)|52.216.186.43|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4721645 (4.5M) [application/zip]\n",
      "Saving to: ‘wikitext-2-raw-v1.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  326K 14s\n",
      "    50K .......... .......... .......... .......... ..........  2% 1.67M 8s\n",
      "   100K .......... .......... .......... .......... ..........  3% 1.02M 7s\n",
      "   150K .......... .......... .......... .......... ..........  4%  122M 5s\n",
      "   200K .......... .......... .......... .......... ..........  5%  658K 5s\n",
      "   250K .......... .......... .......... .......... ..........  6% 81.1M 4s\n",
      "   300K .......... .......... .......... .......... ..........  7% 93.3M 4s\n",
      "   350K .......... .......... .......... .......... ..........  8% 87.8M 3s\n",
      "   400K .......... .......... .......... .......... ..........  9% 1.74M 3s\n",
      "   450K .......... .......... .......... .......... .......... 10% 1.04M 3s\n",
      "   500K .......... .......... .......... .......... .......... 11%  100M 3s\n",
      "   550K .......... .......... .......... .......... .......... 13% 84.3M 3s\n",
      "   600K .......... .......... .......... .......... .......... 14%  103M 2s\n",
      "   650K .......... .......... .......... .......... .......... 15%  119M 2s\n",
      "   700K .......... .......... .......... .......... .......... 16% 85.5M 2s\n",
      "   750K .......... .......... .......... .......... .......... 17%  108M 2s\n",
      "   800K .......... .......... .......... .......... .......... 18%  262M 2s\n",
      "   850K .......... .......... .......... .......... .......... 19% 1.86M 2s\n",
      "   900K .......... .......... .......... .......... .......... 20% 1.05M 2s\n",
      "   950K .......... .......... .......... .......... .......... 21%  110M 2s\n",
      "  1000K .......... .......... .......... .......... .......... 22%  111M 2s\n",
      "  1050K .......... .......... .......... .......... .......... 23%  102M 1s\n",
      "  1100K .......... .......... .......... .......... .......... 24%  125M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 26% 84.6M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 27% 78.7M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 28%  141M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 29%  105M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 30%  124M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 31%  156M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 32%  138M 1s\n",
      "  1500K .......... .......... .......... .......... .......... 33%  239M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 34%  178M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 35% 72.5M 1s\n",
      "  1650K .......... .......... .......... .......... .......... 36%  273M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 37%  296M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 39% 2.05M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 40%  195M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 41% 1.06M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 42% 63.2M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 43% 70.7M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 44% 47.8M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 45% 47.8M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 46% 45.2M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 47% 98.7M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 48% 84.7M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 49%  142M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 50%  203M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 52%  258M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 53%  235M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 54%  235M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 55%  207M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 56%  242M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 57%  255M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 58%  242M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 59%  206M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 60%  241M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 61%  236M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 62%  228M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 63%  215M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 65%  253M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 66%  230M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 67%  237M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 68%  186M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 69%  249M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 70%  233M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 71%  229M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 72% 2.46M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 73%  204M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 74% 1.05M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 75% 49.6M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 76% 67.2M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 78% 46.4M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 79% 57.4M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 80% 61.2M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 81%  232M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 82%  118M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 83%  246M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 84%  274M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 85%  225M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 86%  249M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 87%  293M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 88%  270M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 90%  330M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 91%  308M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 92%  314M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 93%  270M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 94%  286M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 95%  325M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 96%  318M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 97%  276M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 98%  326M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 99%  324M 0s\n",
      "  4600K ..........                                            100%  185M=0.6s\n",
      "\n",
      "2019-11-28 17:40:56 (7.26 MB/s) - ‘wikitext-2-raw-v1.zip’ saved [4721645/4721645]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget http://research.metamind.io.s3.amazonaws.com/wikitext/wikitext-2-raw-v1.zip\n",
    "unzip -n wikitext-2-raw-v1.zip\n",
    "cd wikitext-2-raw\n",
    "mv wiki.test.raw test && mv wiki.train.raw train && mv wiki.valid.raw valid\n",
    "# Moving the pre-divided datasets into Test, Train and Validation directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview what data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " = Valkyria Chronicles III = \n",
      " \n",
      " Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n"
     ]
    }
   ],
   "source": [
    "!head -5 wikitext-2-raw/train\n",
    "#Lets see how the train dataset looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-111652037296/sagemaker/DEMO-pytorch-rnn-lstm\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='wikitext-2-raw', bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "'''\n",
    "S3 object key name prefix (default: ‘data’). S3 uses the prefix to create a directory structure for the bucket content that it display in the S3 console.\n",
    "\n",
    "Tree of the datasets - \n",
    "\n",
    "├── wikitext-2-raw\n",
    "│   ├── test\n",
    "│   ├── train\n",
    "│   └── valid\n",
    "'''\n",
    "\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "We need to provide a training script that can run on the SageMaker platform. The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to.\n",
    "  These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_OUTPUT_DATA_DIR`: A string representing the filesystem path to write output artifacts to. Output artifacts may\n",
    "  include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed\n",
    "  and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method,\n",
    "the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "The script that we will use in this example is stored in GitHub repo \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/tree/training-scripts](https://github.com/awslabs/amazon-sagemaker-examples/tree/training-scripts), \n",
    "under the branch `training-scripts`. It is a public repo so we don't need authentication to access it. Let's specify the `git_config` argument here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance. \n",
    "\n",
    "For example, the script run by this notebook: \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/train.py](https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/train.py). \n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current example we also need to provide source directory, because training script imports data and model classes from other modules. The source directory is \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/](https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/). We should provide 'pytorch-rnn-scripts' for `source_dir` when creating the Estimator object, which is a relative path inside the Git repository. \n",
    "\n",
    "\n",
    "Lets see the training script in details - this training script is located here - \n",
    "\n",
    "```bash\n",
    "├── pytorch-rnn-scripts\n",
    "│   ├── data.py\n",
    "│   ├── generate.py\n",
    "│   ├── __init__.py\n",
    "│   ├── rnn.py\n",
    "│   └── train.py\n",
    "```\n",
    "\n",
    "```python\n",
    "import data\n",
    "```\n",
    "\n",
    "Here we import data.py, data.py has functions for tokenizing and creating a corpus for consumptions. A few relevant details here - [tokens](https://github.com/nicolas-ivanov/tf_seq2seq_chatbot/issues/15#issuecomment-246106807)\n",
    "\n",
    "Then we have hyperparamters being passed to this script, you can see this in the training blob\n",
    "\n",
    "\n",
    "```python\n",
    "# Hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "parser.add_argument('--emsize', type=int, default=200,\n",
    "                    help='size of word embeddings')\n",
    "parser.add_argument('--nhid', type=int, default=200,\n",
    "                    help='number of hidden units per layer')\n",
    "parser.add_argument('--nlayers', type=int, default=2,\n",
    "                    help='number of layers')\n",
    "parser.add_argument('--lr', type=float, default=20,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--clip', type=float, default=0.25,\n",
    "                    help='gradient clipping')\n",
    "parser.add_argument('--epochs', type=int, default=40,\n",
    "                    help='upper epoch limit')\n",
    "parser.add_argument('--batch_size', type=int, default=20, metavar='N',\n",
    "                    help='batch size')\n",
    "parser.add_argument('--bptt', type=int, default=35,\n",
    "                    help='sequence length')\n",
    "parser.add_argument('--dropout', type=float, default=0.2,\n",
    "                    help='dropout applied to layers (0 = no dropout)')\n",
    "parser.add_argument('--tied', type=bool, default=False,\n",
    "                    help='tie the word embedding and softmax weights')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--log-interval', type=int, default=200, metavar='N',\n",
    "                    help='report interval')\n",
    "```\n",
    "Then we have details of file paths - \n",
    "\n",
    "```python\n",
    "# Data and model checkpoints/otput directories from the container environment\n",
    "parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "parser.add_argument('--data-dir', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "```\n",
    "\n",
    "Here are some logs from when a job like this was run - \n",
    "\n",
    "```json\n",
    "SM_TRAINING_ENV=\n",
    "{\n",
    "    \"additional_framework_parameters\": {},\n",
    "    \"channel_input_dirs\": {\n",
    "        \"training\": \"/opt/ml/input/data/training\"\n",
    "    },\n",
    "    \"current_host\": \"algo-1\",\n",
    "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
    "    \"hosts\": [\n",
    "        \"algo-1\"\n",
    "    ],\n",
    "    \"hyperparameters\": {\n",
    "        \"epochs\": 6,\n",
    "        \"tied\": true\n",
    "    },\n",
    "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
    "    \"input_data_config\": {\n",
    "        \"training\": {\n",
    "            \"RecordWrapperType\": \"None\",\n",
    "            \"S3DistributionType\": \"FullyReplicated\",\n",
    "            \"TrainingInputMode\": \"File\"\n",
    "        }\n",
    "    },\n",
    "    \"input_dir\": \"/opt/ml/input\",\n",
    "    \"is_master\": true,\n",
    "    \"job_name\": \"sagemaker-pytorch-2019-11-26-19-32-08-962\",\n",
    "    \"log_level\": 20,\n",
    "    \"master_hostname\": \"algo-1\",\n",
    "    \"model_dir\": \"/opt/ml/model\",\n",
    "    \"module_dir\": \"s3://sagemaker-us-west-2-111652037296/sagemaker-pytorch-2019-11-26-19-32-08-962/source/sourcedir.tar.gz\",\n",
    "    \"module_name\": \"train\",\n",
    "    \"network_interface_name\": \"eth0\",\n",
    "    \"num_cpus\": 4,\n",
    "    \"num_gpus\": 1,\n",
    "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
    "    \"output_dir\": \"/opt/ml/output\",\n",
    "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
    "    \"resource_config\": {\n",
    "        \"current_host\": \"algo-1\",\n",
    "        \"hosts\": [\n",
    "            \"algo-1\"\n",
    "        ],\n",
    "        \"network_interface_name\": \"eth0\"\n",
    "    },\n",
    "    \"user_entry_point\": \"train.py\"\n",
    "}\n",
    "```\n",
    "\n",
    "Here are some environment variables - \n",
    "\n",
    "```json\n",
    "SM_USER_ARGS=[\"--epochs\",\"6\",\"--tied\",\"True\"]\n",
    "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
    "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
    "SM_HP_TIED=true\n",
    "SM_HP_EPOCHS=6\n",
    "PYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
    "Invoking script with the following command:\n",
    "/usr/bin/python -m train --epochs 6 --tied True\n",
    "\n",
    "Namespace(batch_size=20, bptt=35, clip=0.25, data_dir='/opt/ml/input/data/training', dropout=0.2, emsize=200, epochs=6, log_interval=200, lr=20, model_dir='/opt/ml/model', nhid=200, nlayers=2, output_data_dir='/opt/ml/output/data', seed=1111, tied=True)\n",
    "```\n",
    "\n",
    "You can find the logs by going to the training jobs in the Amazon SageMaker Dashboard\n",
    "\n",
    "```python\n",
    "# Set the random seed manually for reproducibility.\n",
    "torch.manual_seed(args.seed)\n",
    "```\n",
    "\n",
    "This seed you can seed was 1111 in the above example. You can use torch.manual_seed() to seed the RNG for all devices (both CPU and CUDA). Completely reproducible results are not guaranteed across PyTorch releases, individual commits or different platforms. Furthermore, results need not be reproducible between CPU and GPU executions, even when using identical seeds. However, in order to make computations deterministic on your specific problem on one specific platform and PyTorch release, there are a couple of steps to take. This is one of these steps. More details [here(https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "\n",
    "\n",
    "Now we load the corpus created by data.py\n",
    "\n",
    "```python\n",
    "print('Load data')\n",
    "corpus = data.Corpus(args.data_dir)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in Pytorch\n",
    "\n",
    "Now at this stage after a bit more setup - we load the model \n",
    "\n",
    "```python\n",
    "ntokens = len(corpus.dictionary)\n",
    "rnn_type = 'LSTM'\n",
    "model = RNNModel(rnn_type, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout, args.tied).to(device)\n",
    "```\n",
    "\n",
    "We have defined the model in - rnn.py\n",
    "\n",
    "We are using LSTM which is a variant of RNN\n",
    "\n",
    "![The LSTM Cell](../img/The_LSTM_cell-600.400.png)\n",
    "\n",
    "Soure of image - [Guillaume Chevalier from Wikipedia](https://en.wikipedia.org/wiki/Long_short-term_memory#/media/File:The_LSTM_cell.png)\n",
    "\n",
    "Now you can see how the above architecture is setup, we can understand this better using the following image as a resource. \n",
    "\n",
    "![The LSTM Cell - in series](../img/nct-seq2seq.png)\n",
    "\n",
    "Soure of image - [Deep Learning for Chatbots, Part 1 – Introduction](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/)\n",
    "\n",
    "```python\n",
    "self.drop = nn.Dropout(dropout)\n",
    "self.encoder = nn.Embedding(ntoken, ninp)\n",
    "self.rnn = getattr(nn, 'LSTM')(ninp, nhid, nlayers, dropout=dropout)\n",
    "\n",
    "nn - Base class for all neural network modules.\n",
    "ninp - size of word embeddings - emsize=200\n",
    "nhid - number of hidden units per layer - nhid=200\n",
    "nlayers - number of layers - nlayers=2\n",
    "dropout - dropout=0.2\n",
    "tied - tie the word embedding and softmax weights - tied=True\n",
    "```\n",
    "\n",
    "Then you can see the necessary functions of RNNs - such as - forward pass and initialize hidden weights. \n",
    "\n",
    "```python\n",
    "def init_weights(self):\n",
    "def forward(self, input, hidden):\n",
    "def init_hidden(self, bsz):\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the training script \n",
    "\n",
    "We have function to batch up the corpus -\n",
    "\n",
    "```python\n",
    "def get_batch(source, i):\n",
    "get_batch subdivides the source data into chunks of length args.bptt.\n",
    "```\n",
    "\n",
    "We have a function for Training, Validation\n",
    "\n",
    "```python\n",
    "def train():\n",
    "def evaluate(data_source):\n",
    "```\n",
    "\n",
    "We have the training loop\n",
    "\n",
    "```python\n",
    "for epoch in range(1, args.epochs+1):\n",
    "```\n",
    "\n",
    "We checkpoint the model - \n",
    "\n",
    "```python\n",
    "print('Saving the best model: {}'.format(best_state))\n",
    "with open(checkpoint_path, 'wb') as f:\n",
    "    torch.save(model.state_dict(), f)\n",
    "with open(checkpoint_state_path, 'w') as f:\n",
    "```\n",
    "    \n",
    "&\n",
    "\n",
    "```python\n",
    "# Load the best saved model.\n",
    "with open(checkpoint_path, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    # after load the rnn params are not a continuous chunk of memory\n",
    "    # this makes them a continuous chunk, and will speed up forward pass\n",
    "    model.rnn.flatten_parameters()\n",
    "```\n",
    "\n",
    "&\n",
    "\n",
    "Save the model - \n",
    "\n",
    "```python\n",
    "# Move the best model to cpu and resave it\n",
    "with open(model_path, 'wb') as f:\n",
    "    torch.save(model.cpu().state_dict(), f)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training in SageMaker\n",
    "The PyTorch class allows us to run our training function as a training job on SageMaker infrastructure. We need to configure it with our training script and source directory, an IAM role, the number of training instances, and the training instance type. In this case we will run our training job on ```ml.p2.xlarge``` instance. As you can see in this example you can also specify hyperparameters. \n",
    "\n",
    "Here we are using a prebuilt container for training our script, if you want to create your own please navigate to - https://github.com/aws/sagemaker-pytorch-container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.2.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    source_dir='pytorch-rnn-scripts',\n",
    "                    # available hyperparameters: emsize, nhid, nlayers, lr, clip, epochs, batch_size,\n",
    "                    #                            bptt, dropout, tied, seed, log_interval\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6,\n",
    "                        'tied': True\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our PyTorch object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-28 17:40:58 Starting - Starting the training job...\n",
      "2019-11-28 17:40:59 Starting - Launching requested ML instances......\n",
      "2019-11-28 17:41:59 Starting - Preparing the instances for training.........\n",
      "2019-11-28 17:43:43 Downloading - Downloading input data...\n",
      "2019-11-28 17:44:15 Training - Downloading the training image............\n",
      "2019-11-28 17:46:25 Training - Training image download completed. Training in progress..\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:26,729 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:26,754 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:26,755 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:27,008 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:27,009 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:27,009 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:27,009 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=23673 sha256=79ec53a71c3db37cb6d6bf9b37ac4aed1cdffc669a45b52484a111788e6ec3b0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iokozj_8/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built train\u001b[0m\n",
      "\u001b[31mInstalling collected packages: train\u001b[0m\n",
      "\u001b[31mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[31mWARNING: You are using pip version 19.3; however, version 19.3.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-11-28 17:46:29,003 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"tied\": true,\n",
      "        \"epochs\": 6\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2019-11-28-17-40-57-666\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-111652037296/pytorch-training-2019-11-28-17-40-57-666/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"epochs\":6,\"tied\":true}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-west-2-111652037296/pytorch-training-2019-11-28-17-40-57-666/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":6,\"tied\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2019-11-28-17-40-57-666\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-111652037296/pytorch-training-2019-11-28-17-40-57-666/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--epochs\",\"6\",\"--tied\",\"True\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_HP_TIED=true\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=6\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/opt/conda/bin/python -m train --epochs 6 --tied True\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mNamespace(batch_size=20, bptt=35, clip=0.25, data_dir='/opt/ml/input/data/training', dropout=0.2, emsize=200, epochs=6, log_interval=200, lr=20, model_dir='/opt/ml/model', nhid=200, nlayers=2, output_data_dir='/opt/ml/output/data', seed=1111, tied=True)\u001b[0m\n",
      "\u001b[31mLoad data\u001b[0m\n",
      "\u001b[31mBatchify dataset\u001b[0m\n",
      "\u001b[31mBuild the model\u001b[0m\n",
      "\u001b[31mStarting training.\u001b[0m\n",
      "\u001b[31m| epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 87.63 | loss  8.33 | ppl  4136.34\u001b[0m\n",
      "\u001b[31m| epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 87.27 | loss  7.38 | ppl  1606.61\u001b[0m\n",
      "\u001b[31m| epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 87.55 | loss  6.87 | ppl   964.80\u001b[0m\n",
      "\u001b[31m| epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 87.79 | loss  6.68 | ppl   794.86\u001b[0m\n",
      "\u001b[31m| epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 88.11 | loss  6.45 | ppl   632.29\u001b[0m\n",
      "\u001b[31m| epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 88.21 | loss  6.39 | ppl   595.52\u001b[0m\n",
      "\u001b[31m| epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 88.27 | loss  6.31 | ppl   548.38\u001b[0m\n",
      "\u001b[31m| epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 88.39 | loss  6.29 | ppl   539.20\u001b[0m\n",
      "\u001b[31m| epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 88.57 | loss  6.08 | ppl   436.73\u001b[0m\n",
      "\u001b[31m| epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 88.73 | loss  6.05 | ppl   422.07\u001b[0m\n",
      "\u001b[31m| epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 88.68 | loss  5.92 | ppl   371.01\u001b[0m\n",
      "\u001b[31m| epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 88.72 | loss  5.96 | ppl   388.87\u001b[0m\n",
      "\u001b[31m| epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 88.89 | loss  5.94 | ppl   379.04\u001b[0m\n",
      "\u001b[31m| epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 88.79 | loss  5.83 | ppl   340.01\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31m| end of epoch   1 | time: 272.56s | valid loss  6.03 | valid ppl   416.09\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31mSaving the best model: {'epoch': 1, 'lr': 20, 'val_loss': 6.030891246884169, 'val_ppl': 416.0856992612763}\u001b[0m\n",
      "\u001b[31m| epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 89.27 | loss  5.83 | ppl   341.53\u001b[0m\n",
      "\u001b[31m| epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 88.82 | loss  5.80 | ppl   330.97\u001b[0m\n",
      "\u001b[31m| epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 88.94 | loss  5.60 | ppl   271.56\u001b[0m\n",
      "\u001b[31m| epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 88.90 | loss  5.62 | ppl   277.13\u001b[0m\n",
      "\u001b[31m| epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 89.03 | loss  5.52 | ppl   249.90\u001b[0m\n",
      "\u001b[31m| epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 88.88 | loss  5.55 | ppl   257.81\u001b[0m\n",
      "\u001b[31m| epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 88.91 | loss  5.59 | ppl   268.73\u001b[0m\n",
      "\u001b[31m| epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 88.97 | loss  5.65 | ppl   284.16\u001b[0m\n",
      "\u001b[31m| epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 89.05 | loss  5.48 | ppl   239.59\u001b[0m\n",
      "\u001b[31m| epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 89.04 | loss  5.49 | ppl   241.56\u001b[0m\n",
      "\u001b[31m| epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 89.05 | loss  5.39 | ppl   219.18\u001b[0m\n",
      "\u001b[31m| epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 88.92 | loss  5.45 | ppl   233.92\u001b[0m\n",
      "\u001b[31m| epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 88.99 | loss  5.46 | ppl   236.21\u001b[0m\n",
      "\u001b[31m| epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 89.18 | loss  5.38 | ppl   217.57\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31m| end of epoch   2 | time: 274.70s | valid loss  5.75 | valid ppl   314.53\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31mSaving the best model: {'epoch': 2, 'lr': 20, 'val_loss': 5.751095302971249, 'val_ppl': 314.53498278374815}\u001b[0m\n",
      "\u001b[31m| epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 89.24 | loss  5.45 | ppl   232.43\u001b[0m\n",
      "\u001b[31m| epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 88.98 | loss  5.45 | ppl   233.06\u001b[0m\n",
      "\u001b[31m| epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 89.14 | loss  5.25 | ppl   191.17\u001b[0m\n",
      "\u001b[31m| epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 89.08 | loss  5.30 | ppl   200.75\u001b[0m\n",
      "\u001b[31m| epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 88.97 | loss  5.22 | ppl   185.25\u001b[0m\n",
      "\u001b[31m| epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 89.06 | loss  5.27 | ppl   193.69\u001b[0m\n",
      "\u001b[31m| epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 89.08 | loss  5.33 | ppl   207.32\u001b[0m\n",
      "\u001b[31m| epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 89.11 | loss  5.40 | ppl   221.43\u001b[0m\n",
      "\u001b[31m| epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 89.16 | loss  5.23 | ppl   187.49\u001b[0m\n",
      "\u001b[31m| epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 89.20 | loss  5.26 | ppl   192.34\u001b[0m\n",
      "\u001b[31m| epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 89.25 | loss  5.16 | ppl   173.74\u001b[0m\n",
      "\u001b[31m| epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 89.25 | loss  5.23 | ppl   186.43\u001b[0m\n",
      "\u001b[31m| epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 89.17 | loss  5.25 | ppl   190.77\u001b[0m\n",
      "\u001b[31m| epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 89.42 | loss  5.18 | ppl   177.47\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31m| end of epoch   3 | time: 275.17s | valid loss  5.65 | valid ppl   283.93\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31mSaving the best model: {'epoch': 3, 'lr': 20, 'val_loss': 5.648728454820682, 'val_ppl': 283.9302061087303}\u001b[0m\n",
      "\u001b[31m| epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 89.74 | loss  5.25 | ppl   190.49\u001b[0m\n",
      "\u001b[31m| epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 89.36 | loss  5.27 | ppl   193.59\u001b[0m\n",
      "\u001b[31m| epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 89.48 | loss  5.06 | ppl   157.97\u001b[0m\n",
      "\u001b[31m| epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 89.51 | loss  5.13 | ppl   168.75\u001b[0m\n",
      "\u001b[31m| epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 89.40 | loss  5.05 | ppl   156.66\u001b[0m\n",
      "\u001b[31m| epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 89.42 | loss  5.11 | ppl   165.33\u001b[0m\n",
      "\u001b[31m| epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 89.48 | loss  5.18 | ppl   176.89\u001b[0m\n",
      "\u001b[31m| epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 89.74 | loss  5.24 | ppl   189.53\u001b[0m\n",
      "\u001b[31m| epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 89.62 | loss  5.09 | ppl   162.49\u001b[0m\n",
      "\u001b[31m| epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 89.52 | loss  5.12 | ppl   167.23\u001b[0m\n",
      "\u001b[31m| epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 89.52 | loss  5.02 | ppl   151.02\u001b[0m\n",
      "\u001b[31m| epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 89.52 | loss  5.09 | ppl   162.49\u001b[0m\n",
      "\u001b[31m| epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 89.50 | loss  5.12 | ppl   166.55\u001b[0m\n",
      "\u001b[31m| epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 89.58 | loss  5.05 | ppl   155.38\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31m| end of epoch   4 | time: 276.28s | valid loss  5.60 | valid ppl   270.80\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31mSaving the best model: {'epoch': 4, 'lr': 20, 'val_loss': 5.601393558680628, 'val_ppl': 270.803525200536}\u001b[0m\n",
      "\u001b[31m| epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 90.08 | loss  5.12 | ppl   167.99\u001b[0m\n",
      "\u001b[31m| epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 89.47 | loss  5.14 | ppl   170.05\u001b[0m\n",
      "\u001b[31m| epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 89.64 | loss  4.94 | ppl   139.46\u001b[0m\n",
      "\u001b[31m| epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 89.62 | loss  5.00 | ppl   149.02\u001b[0m\n",
      "\u001b[31m| epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 89.67 | loss  4.95 | ppl   140.72\u001b[0m\n",
      "\u001b[31m| epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 89.67 | loss  5.00 | ppl   148.11\u001b[0m\n",
      "\u001b[31m| epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 89.55 | loss  5.07 | ppl   158.69\u001b[0m\n",
      "\u001b[31m| epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 89.54 | loss  5.14 | ppl   170.79\u001b[0m\n",
      "\u001b[31m| epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 89.48 | loss  4.98 | ppl   145.98\u001b[0m\n",
      "\u001b[31m| epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 89.67 | loss  5.02 | ppl   151.35\u001b[0m\n",
      "\u001b[31m| epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 89.62 | loss  4.91 | ppl   135.80\u001b[0m\n",
      "\u001b[31m| epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 89.76 | loss  4.98 | ppl   145.65\u001b[0m\n",
      "\u001b[31m| epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 89.70 | loss  5.01 | ppl   149.46\u001b[0m\n",
      "\u001b[31m| epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 89.74 | loss  4.95 | ppl   140.62\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31m| end of epoch   5 | time: 276.69s | valid loss  5.58 | valid ppl   265.60\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31mSaving the best model: {'epoch': 5, 'lr': 20, 'val_loss': 5.582009914122485, 'val_ppl': 265.60491272120066}\u001b[0m\n",
      "\u001b[31m| epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 90.11 | loss  5.02 | ppl   151.79\u001b[0m\n",
      "\u001b[31m| epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 89.69 | loss  5.04 | ppl   153.73\u001b[0m\n",
      "\u001b[31m| epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 89.74 | loss  4.84 | ppl   126.57\u001b[0m\n",
      "\u001b[31m| epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 89.71 | loss  4.91 | ppl   135.96\u001b[0m\n",
      "\u001b[31m| epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 89.68 | loss  4.86 | ppl   129.46\u001b[0m\n",
      "\u001b[31m| epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 89.72 | loss  4.92 | ppl   136.79\u001b[0m\n",
      "\u001b[31m| epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 89.65 | loss  4.98 | ppl   145.84\u001b[0m\n",
      "\u001b[31m| epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 89.62 | loss  5.05 | ppl   156.77\u001b[0m\n",
      "\u001b[31m| epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 89.63 | loss  4.91 | ppl   135.50\u001b[0m\n",
      "\u001b[31m| epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 89.64 | loss  4.94 | ppl   139.67\u001b[0m\n",
      "\u001b[31m| epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 89.63 | loss  4.84 | ppl   125.85\u001b[0m\n",
      "\u001b[31m| epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 89.62 | loss  4.90 | ppl   134.81\u001b[0m\n",
      "\u001b[31m| epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 89.64 | loss  4.93 | ppl   138.93\u001b[0m\n",
      "\u001b[31m| epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 89.70 | loss  4.88 | ppl   131.10\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31m| end of epoch   6 | time: 276.77s | valid loss  5.56 | valid ppl   258.59\u001b[0m\n",
      "\u001b[31m-----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[31mSaving the best model: {'epoch': 6, 'lr': 20, 'val_loss': 5.555247321546878, 'val_ppl': 258.5909117167824}\u001b[0m\n",
      "\n",
      "2019-11-28 18:14:39 Uploading - Uploading generated training model\u001b[31m=========================================================================================\u001b[0m\n",
      "\u001b[31m| End of training | test loss  5.57 | test ppl   262.91\u001b[0m\n",
      "\u001b[31m=========================================================================================\u001b[0m\n",
      "\u001b[31m2019-11-28 18:14:39,240 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-11-28 18:15:00 Completed - Training job completed\n",
      "Training seconds: 1877\n",
      "Billable seconds: 1877\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How we monitor training \n",
    "\n",
    "```python\n",
    "| epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 89.25 | loss  5.16 | ppl   173.74\n",
    "```\n",
    "\n",
    "epoch - is the current turn of the loop for training - for each epoch we go through the entire training dataset\n",
    "batches - as we saw before we have split up training in batches also check [here](https://datascience.stackexchange.com/questions/16807/why-mini-batch-size-is-better-than-one-single-batch-with-all-training-data)\n",
    "\n",
    "& from Yann LeCun's facebook - \n",
    "\n",
    ">Training with large minibatches is bad for your health. More importantly, it's bad for your test error. Friends dont let friends use minibatches larger than 32. Let's face it: the only people have switched to minibatch sizes larger than one since 2012 is because GPUs are inefficient for batch sizes smaller than 32. That's a terrible reason. It just means our hardware sucks.\n",
    "\n",
    "lr - Learning Rate - more (here)[https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/] and (here)[https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/]\n",
    "Learning rate is at the rate at which our model updates the weights in the cells each time back-propogation is done. \n",
    "\n",
    "ms/batch - time taken per batch\n",
    "\n",
    "loss - current training loss, and the end of epoch we calculate validation loss\n",
    "\n",
    "ppl - this is math.exp(loss) - but why we print and track here other than signalling a change in the loss value. #TODO - if someone knows this better please submit a pull request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://instacalc.com/53287/embed\" width=\"450\" height=\"350\" frameborder=\"0\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://instacalc.com/53287/embed\" width=\"450\" height=\"350\" frameborder=\"0\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host\n",
    "### Hosting script\n",
    "We are going to provide custom implementation of `model_fn`, `input_fn`, `output_fn` and `predict_fn` hosting functions in a separate file, which is in the same Git repo as the training script: \n",
    "[https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/generate.py](https://github.com/awslabs/amazon-sagemaker-examples/blob/training-scripts/pytorch-rnn-scripts/generate.py). \n",
    "We will use Git integration for hosting too since the hosting code is also in the Git repo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also put your training and hosting code in the same file but you would need to add a main guard (`if __name__=='__main__':`) for the training code, so that the container does not inadvertently run it at the wrong point in execution during hosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets dissect generate.py's hosting methods\n",
    "\n",
    "Please note: Following explanations have been adapted from Chainer continer examples, for a more detailed and authoratative description please go [here](https://github.com/aws/sagemaker-python-sdk/blob/fa14b32e63087d9f9a0bdbf63e9e39d151975dec/doc/using_pytorch.rst)\n",
    "\n",
    "```python\n",
    "from rnn import RNNModel\n",
    "```\n",
    "\n",
    "We start with importing the basic RNN from rnn.py\n",
    "\n",
    "```python\n",
    "def model_fn(model_dir):\n",
    "    model_info = torch.load(f)\n",
    "    model.load_state_dict(torch.load(f))\n",
    "    model.to(device).eval()\n",
    "    corpus = data.Corpus(model_dir)\n",
    "    \n",
    "    \"\"\"\n",
    "    Before a model can be served, it must be loaded. The SageMaker PyTorch model server loads your model by invoking a model_fn\n",
    "    function that you must provide in your script. The model_fn should have the following signature:\n",
    "    \n",
    "    def model_fn(model_dir)\n",
    "    \n",
    "    SageMaker will inject the directory where your model files and sub-directories, saved by save, have been mounted. \n",
    "    Your model function should return a model object that can be used for model serving.\n",
    "    \n",
    "    This function is called by the Pytroch container during hosting when running on SageMaker with\n",
    "    values populated by the hosting environment.\n",
    "    \n",
    "    This function loads models written during training into `model_dir`.\n",
    "    Args:\n",
    "        model_dir (str): path to the directory containing the saved model artifacts\n",
    "    Returns:\n",
    "        a loaded Pytorch model\n",
    "    For more on `model_fn`, please visit the sagemaker-python-sdk repository:\n",
    "    https://github.com/aws/sagemaker-python-sdk/blob/fa14b32e63087d9f9a0bdbf63e9e39d151975dec/doc/using_pytorch.rst\n",
    "    For more on the Pytorch container, please visit the sagemaker-pytorch-containers repository:\n",
    "    https://github.com/aws/sagemaker-pytorch-container\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "```\n",
    "\n",
    "It deals with loading the model and the corups. [A common PyTorch convention](https://pytorch.org/tutorials/beginner/saving_loading_models.html) is to save models using either a .pt or .pth file extension. \n",
    "\n",
    "```python\n",
    "    def input_fn(serialized_input_data, content_type=JSON_CONTENT_TYPE):\n",
    "    \n",
    "    \"\"\"This function is called on the byte stream sent by the client, and is used to deserialize the\n",
    "    bytes into a Python object suitable for inference by predict_fn -- in this case, a NumPy array.\n",
    "    \n",
    "    This implementation is effectively identical to the default implementation used in the Pytorch\n",
    "    container, for NPY formatted data. This function is included in this script to demonstrate\n",
    "    how one might implement `input_fn`.\n",
    "    Args:\n",
    "        input_bytes (numpy array): a numpy array containing the data serialized by the PyTorch predictor\n",
    "        content_type: the MIME type of the data in input_bytes\n",
    "    Returns:\n",
    "        a NumPy array represented by input_bytes.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "Deals with deserializing the input data. \n",
    "\n",
    "\n",
    "```python\n",
    "    def predict_fn(input_data, model):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a NumPy array and makes a prediction on it using the model returned\n",
    "    by `model_fn`.\n",
    "    \n",
    "    The default predictor used by `PyTorch` serializes input data to the 'npy' format:\n",
    "    https://docs.scipy.org/doc/numpy-1.14.0/neps/npy-format.html\n",
    "    The PyTorch container provides an overridable pre-processing function `input_fn`\n",
    "    that accepts the serialized input data and deserializes it into a NumPy array.\n",
    "    `input_fn` is invoked before `predict_fn` and passes its return value to this function\n",
    "    (as `input_data`)\n",
    "    \n",
    "    The PyTorch container provides an overridable post-processing function `output_fn`\n",
    "    that accepts this function's return value and serializes it back into `npy` format, which\n",
    "    the PyTorch predictor can deserialize back into a NumPy array on the client.\n",
    "    Args:\n",
    "        input_data: a numpy array containing the data serialized by the PyTorch predictor\n",
    "        model: the return value of `model_fn`\n",
    "    Returns:\n",
    "        a NumPy array containing predictions which will be returned to the client\n",
    "```\n",
    "\n",
    "& Finally\n",
    "\n",
    "```python\n",
    "    def output_fn(prediction_output, accept=JSON_CONTENT_TYPE):\n",
    "\n",
    "    \"\"\"This function is called on the return value of predict_fn, and is used to serialize the\n",
    "    predictions back to the client.\n",
    "    \n",
    "    This implementation is effectively identical to the default implementation used in the PyTorch\n",
    "    container, for NPY formatted data. This function is included in this script to demonstrate\n",
    "    how one might implement `output_fn`.\n",
    "    Args:\n",
    "        prediction_output (numpy array): a numpy array containing the data serialized by the PyTorch predictor\n",
    "        accept: the MIME type of the data expected by the client.\n",
    "    Returns:\n",
    "        a tuple containing a serialized NumPy array and the MIME type of the serialized data.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model into SageMaker\n",
    "The PyTorch model uses a npy serializer and deserializer by default. For this example, since we have a custom implementation of all the hosting functions and plan on using JSON instead, we need a predictor that can serialize and deserialize JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor, json_serializer, json_deserializer\n",
    "\n",
    "class JSONPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(JSONPredictor, self).__init__(endpoint_name, sagemaker_session, json_serializer, json_deserializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since hosting functions implemented outside of train script we can't just use estimator object to deploy the model. Instead we need to create a PyTorchModel object using the latest training job to get the S3 location of the trained model data. Besides model data location in S3, we also need to configure PyTorchModel with the script and source directory (because our `generate` script requires model and data classes from source directory), an IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "desc = sagemaker_session.sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "trained_model_location = desc['ModelArtifacts']['S3ModelArtifacts']\n",
    "model = PyTorchModel(model_data=trained_model_location,\n",
    "                     role=role,\n",
    "                     framework_version='1.0.0',\n",
    "                     entry_point='generate.py',\n",
    "                     source_dir='pytorch-rnn-scripts',\n",
    "                     predictor_cls=JSONPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyTorchModel constructor takes the following arguments:\n",
    "\n",
    "* model_dat: An S3 location of a SageMaker model data .tar.gz file\n",
    "* role: An IAM role name or Arn for SageMaker to access AWS resources on your behalf.\n",
    "* predictor_cls: A function to call to create a predictor. If not None, deploy will return the result of invoking this function on the created endpoint name\n",
    "* entry_point: Path (absolute or relative) to the Python file which should be executed as the entry point to model hosting.\n",
    "* source_dir: Optional. Path (absolute or relative) to a directory with any other training source code dependencies including tne entry point file. Structure within this directory will be preserved when training on SageMaker.\n",
    "* sagemaker_session: The SageMaker Session object, used for SageMaker interaction\n",
    "\n",
    "Your model data must be a .tar.gz file in S3. SageMaker Training Job model data is saved to .tar.gz files in S3, however if you have local data you want to deploy, you can prepare the data yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "\n",
    "Now the model is ready to be deployed at a SageMaker endpoint and we are going to use the `sagemaker.pytorch.model.PyTorchModel.deploy` method to do this. We can use a CPU-based instance for inference (in this case an ml.m4.xlarge), even though we trained on GPU instances, because at the end of training we moved model to cpu before returning it. This way we can load trained model on any device and then move to GPU if CUDA is available. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "We are going to use our deployed model to generate text by providing random seed, temperature (higher will increase diversity) and number of words we would like to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422nd wetland Potro integrating Eighty Demand lanyard sanctified Cévennes agendas detonations apology\n",
      "Escorial DeMille Charlynch helix Zeffirelli Victorien Hessian PRG imitators sheath barbershops Suresnes\n",
      "classifications roaming Alford RPGs guts Marshall Godrich Briefing Branislav 560 Roscoe souls\n",
      "beheaded Borough AIL Shoko Cowper Potworowski goalkeepers Kenith Roumette Ortona Ismailia S.259\n",
      "Wreath partied Bag survived applications annealed fisherman Plains luncheon Đình Tokyo heckles\n",
      "egos Dobson Aag HevyDevy Investigates able Hoodoo Hendrie quatre Needled Prussian visitor\n",
      "Hashomer Redfearn Matteino Stjepan Yiwu Bree roof Surdas simpler Measure bey 411\n",
      "Babang widened Altrock Kulukundis Maverick Wing startling Kostrzewska Featley emails yes Odetta\n",
      "Venture grammars Nachtigall Franka silence Kommunistblad 837 emcee 562 hOWLetts deducted reproductive\n",
      "traveller difficult Rogatti 90s Casino Tracey Screen sabotaging Udell abdicated anglica College\n",
      "lengthy Yuji Nonsense Forth realistic Ioke Quitman repairs Isonomy Costanza Eternia wingers\n",
      "moneyed interferometer impoverishing medicine sentimentality legume 239Pu turning obtains Beautiful Li Locks\n",
      "Sackheim stimmi bombardment flashy hibernate millinery Prover Celeste memoir declination Venu pectoral\n",
      "bright inamyloidy Silverman 549th liability Sangidu chimes Nye Pursey Katalog Gowri morphs\n",
      "condense Tecomán bipinnate Gilmore Marburg Sahel Bains allure spatializer Pogi dole Spence\n",
      "achieving satirist tripped clarity electrocyclizations Roussel Megabus frustrating lagena paratransgenesis neater Forgive\n",
      "1650 Yanow lethal rabbit jolly enactments inventory callback \n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    'seed': 200,\n",
    "    'temperature': 510.0,\n",
    "    'words': 200\n",
    "}\n",
    "response = predictor.predict(input)\n",
    "print(response)\n",
    "\n",
    "#TODO - train GPT-2 in a similar setting and generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
