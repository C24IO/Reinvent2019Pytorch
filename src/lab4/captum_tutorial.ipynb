{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting text models: IMDB sentiment analysis\n",
    "\n",
    "Captum (“comprehension” in Latin) is an open source, extensible library for model interpretability built on PyTorch. The primary audiences for Captum are model developers who are looking to improve their models and understand which features are important and interpretability researchers focused on identifying algorithms that can better interpret many types of models.\n",
    "\n",
    "#### Sources: \n",
    "* https://captum.ai/tutorials/IMDB_TorchText_Interpret\n",
    "* https://captum.ai/docs/introduction.html\n",
    "* https://captum.ai/docs/extension/integrated_gradients\n",
    "* https://arxiv.org/pdf/1703.01365.pdf\n",
    "* https://towardsdatascience.com/interpretable-neural-networks-45ac8aa91411\n",
    "* https://github.com/ankurtaly/Integrated-Gradients\n",
    "* http://theory.stanford.edu/~ataly/Talks/sri_attribution_talk_jun_2017.pdf\n",
    "* https://medium.com/@kartikeyabhardwaj98/integrated-gradients-for-deep-neural-networks-c114e3968eae\n",
    "* http://www.unofficialgoogledatascience.com/2017/03/attributing-deep-networks-prediction-to.html\n",
    "* https://psturmfels.github.io/VisualizingExpectedGradients/\n",
    "* https://www.youtube.com/watch?v=iVSIFm0UN9I\n",
    "* https://medium.com/@SeoJaeDuk/archived-post-axiomatic-attribution-for-deep-networks-b4af79d5ed32\n",
    "* http://pages.cs.wisc.edu/~jiefeng/docs/neurips2019/poster.pdf\n",
    "* http://pages.cs.wisc.edu/~jiefeng/docs/neurips2019/slides.pdf\n",
    "* https://vimeo.com/238242575"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get ready to execute this on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (19.3.1)\n",
      "Requirement already satisfied: torchtext in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (7.352.0)\n",
      "Requirement already satisfied: captum in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.1.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (2.20.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.15.4)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (4.36.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.11.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext) (1.3.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from captum) (3.0.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext) (1.23)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->captum) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->captum) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->captum) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib->captum) (2.7.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->captum) (39.1.0)\n",
      "Requirement already up-to-date: spacy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.3)\n",
      "Requirement already up-to-date: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.3.1)\n",
      "Requirement already up-to-date: msgpack in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (2.20.0)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: thinc<7.4.0,>=7.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (39.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.36.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from more-itertools->zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (1.11.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (39.1.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.15.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.36.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.9.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.1.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from more-itertools->zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.11.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "====================== Installed models (spaCy v2.2.3) ======================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation:\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/spacy\u001b[0m\n",
      "\n",
      "TYPE      NAME             MODEL            VERSION                            \n",
      "package   en-core-web-sm   en_core_web_sm   \u001b[38;5;2m2.2.5\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "link      en               en_core_web_sm   \u001b[38;5;2m2.2.5\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install --upgrade pip\n",
    "pip install torchtext nvidia-ml-py3 captum\n",
    "pip install -U spacy torch msgpack\n",
    "python -m spacy download en\n",
    "python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import InterpretableEmbeddingBase, TokenReferenceBase\n",
    "from captum.attr import visualization\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -cv https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!mkdir data models\n",
    "!(cd data ; wget -cv https://ar51.s3.amazonaws.com/aclImdb_v1.tar.gz)\n",
    "!(cd data ; tar -xzf aclImdb_v1.tar.gz)\n",
    "!(cd models ; wget -cv https://ar51.s3.amazonaws.com/imdb-model-cnn.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        #text = text.permute(1, 0)\n",
    "        #text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/imdb-model-cnn.pt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_sigmoid(input):\n",
    "    return torch.sigmoid(model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(lower=True, tokenize='spacy')\n",
    "Label = torchtext.data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = torchtext.datasets.IMDB.splits(text_field=TEXT,\n",
    "                                      label_field=Label,\n",
    "                                      train='train',\n",
    "                                      test='test',\n",
    "                                      path='data/aclImdb')\n",
    "test, _ = test.split(split_ratio = 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -cv http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!(cd data ; wget -cv https://ar51.s3.amazonaws.com/glove.6B.50d.txt.tar.gz)\n",
    "!(cd data ; tar -xzf glove.6B.50d.txt.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/glove.6B.50d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab\n",
    "\n",
    "#loaded_vectors = vocab.GloVe(name='6B', dim=50)\n",
    "\n",
    "# If you prefer to use pre-downloaded glove vectors, you can load them with the following two command line\n",
    "loaded_vectors = torchtext.vocab.Vectors('data/glove.6B.50d.txt')\n",
    "TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
    "    \n",
    "TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
    "Label.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vocabulary Size: ', len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IND = TEXT.vocab.stoi['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model, sentence, min_len = 7, label = 0):\n",
    "    model.eval()\n",
    "    text = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(text) < min_len:\n",
    "        text += ['pad'] * (min_len - len(text))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in text]\n",
    "\n",
    "    \n",
    "    model.zero_grad()\n",
    "\n",
    "    input_indices = torch.LongTensor(indexed)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "    \n",
    "    # input_indices dim: [sequence_length]\n",
    "    seq_length = min_len\n",
    "\n",
    "    # pre-computing word embeddings\n",
    "    input_embedding = interpretable_embedding.indices_to_embeddings(input_indices)\n",
    "\n",
    "    # predict\n",
    "    pred = forward_with_sigmoid(input_embedding).item()\n",
    "    pred_ind = round(pred)\n",
    "\n",
    "    # generate reference for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "    reference_embedding = interpretable_embedding.indices_to_embeddings(reference_indices)\n",
    "\n",
    "    # compute attributions and approximation delta using integrated gradients\n",
    "    attributions_ig, delta = ig.attribute(input_embedding, reference_embedding, n_steps=500, return_convergence_delta=True)\n",
    "\n",
    "    print('pred: ', Label.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "    \n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            Label.vocab.itos[pred_ind],\n",
    "                            Label.vocab.itos[label],\n",
    "                            Label.vocab.itos[1],\n",
    "                            attributions.sum(),       \n",
    "                            text[:len(attributions)],\n",
    "                            delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_sentence(model, 'It was a fantastic performance !', label=1)\n",
    "interpret_sentence(model, 'Best film ever', label=1)\n",
    "interpret_sentence(model, 'Such a great show!', label=1)\n",
    "interpret_sentence(model, 'It was a horrible movie', label=0)\n",
    "interpret_sentence(model, 'I\\'ve never watched something as bad', label=0)\n",
    "interpret_sentence(model, 'It is a disgusting movie!', label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "visualization.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_records_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='img/sentiment_analysis.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
